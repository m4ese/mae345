{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following few cells setup the neural networks, provide a few helper functions, and connect to the jetbot's motors and camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, do not modify \n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from jetbot import Robot, Camera, ObjectDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the neural networks for detecting objects in the coco dataset, and determining if there will be a collision:\n",
    "\n",
    "- Detect objects in the coco dataset: [ssd_mobilenet_v2_coco.engine](https://drive.google.com/file/d/1KjlDMRD8uhgQmQK-nC2CZGHFTbq4qQQH/view). A list of the object ids can be found [here](https://github.com/tensorflow/models/blob/master/research/object_detection/data/mscoco_complete_label_map.pbtxt).\n",
    "\n",
    "- Pretrained collision avoidance network: [best_model.pth](https://drive.google.com/file/d/1UsRax8bR3R-e-0-80KfH2zAt-IyRPtnW/view)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up models\n",
    "\n",
    "# Setup collision avoidance model from best_model.pth\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "\n",
    "# For Part III, you do not need do not modify this line\n",
    "# PART IV (i) and (ii), replace network line with <your_model>.pth, which you trained in google collab. \n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Moving the model onto the gpu \n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "# Setup coco model from ssd_mobilenet_v2_coco.engine\n",
    "coco_model = ObjectDetector('ssd_mobilenet_v2_coco.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to camera and robot, do not modify\n",
    "\n",
    "# Need 300x300 image for coco dataset's NN, downsampled to 224 when using collision avoidance network\n",
    "camera = Camera.instance(width=300, height=300)\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "def get_network_outputs(image):\n",
    "    '''\n",
    "    Runs the image through both networks, returns network outputs and a rescaled version of the image\n",
    "    Example use if previous cells have been executed:\n",
    "    \n",
    "    prob_blocked, detections = get_network_outputs(camera.value)\n",
    "    ''' \n",
    "    coco_x = image\n",
    "    detections = coco_model(coco_x)\n",
    "\n",
    "    compressed_image = cv2.resize(image, (224, 224))\n",
    "    y = model(preprocess(compressed_image))\n",
    "    y = F.softmax(y, dim=1)\n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "\n",
    "    # Uncomment the following line when you are working on Part IV:\n",
    "    # log(prob_blocked, compressed_image)\n",
    "    \n",
    "    return (prob_blocked, detections)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell provides functions which you will need in Part IV. \n",
    "We ask that you to include the first person view (FPV) of your jetbot as well as a log of the network's output\n",
    "\n",
    "Make sure to uncomment the log(prob_blocked, x) line in the get_network_outputs() function.\n",
    "Example use if previous cells have been executed:\n",
    "\n",
    "FPV_filename = 'PartIV_LogFPV'\n",
    "prob_blocked_filename = 'PartIV_LogProbBlocked'\n",
    "start_logger(FPV_filename)\n",
    "\n",
    "for i in range(50):\n",
    "    prob_blocked, detections = get_network_outputs(camera.value)  \n",
    "    \n",
    "    time.sleep(0.05)\n",
    "\n",
    "stop_logger(prob_blocked_filename)\n",
    "'''\n",
    "video_logger = None \n",
    "prob_blocked_logger = None \n",
    "\n",
    "def start_logger(FPV_filename):\n",
    "    global video_logger, prob_blocked_logger\n",
    "    video_logger = cv2.VideoWriter(FPV_filename + '.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (224, 224))\n",
    "    prob_blocked_logger = []\n",
    "\n",
    "def log(prob_blocked, image):\n",
    "    global video_logger, prob_blocked_logger\n",
    "    video_logger.write(image)\n",
    "    prob_blocked_logger.append(prob_blocked)\n",
    "    \n",
    "def stop_logger(prob_blocked_filename):\n",
    "    global video_logger, prob_blocked_logger\n",
    "    np.save(prob_blocked_filename, prob_blocked_logger)\n",
    "    video_logger.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement your method below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
